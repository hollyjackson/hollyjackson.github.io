
@inproceedings{aocb19,
  title   = "Data Enrichment: Multi-task Learning in High Dimension with Theoretical Guarantees",
  author  = {Asiaee, Amir and Oymak, Samet and Coombes, Kevin R. and Banerjee, Arindam},
  abstract = {Given samples from a group of related regres-sion tasks, a data-enriched model describes ob-servations by a common and per-group individual parameters. In high-dimensional regime, each pa-rameter has its own structure such as sparsity or group sparsity. In this paper, we consider the gen-eral form of data enrichment where data comes in a fixed but arbitrary number of tasks G and any convex function, e.g., norm, can character-ize the structure of both common and individual parameters. We propose an estimator for the high-dimensional data enriched model and investigate its statistical properties. We delineate the sam-ple complexity of our estimator and provide high probability non-asymptotic bound for estimation error of all parameters under a condition weaker than the state-of-the-art. We propose an itera-tive estimation algorithm with a geometric con-vergence rate. Overall, we present a first through statistical and computational analysis of inference in the data enriched model.},
  booktitle = "Adaptive and Multi-Task Learning Workshop at ICML 2019",
  year    =  2019
}


@inproceedings{ascb16,
  title={High Dimensional Structured Estimation with Noisy Designs},
  author={Asiaee T., Amir and Chaterjee, Soumyadeep and Banerjee, Arindam},
  booktitle={16th SIAM International Conference on Data Mining (SDM)},
  pages={801--809},
  year={2016},
  abstract={Structured estimation methods, such as LASSO, have received considerable attention in recent years and substantial progress has been made in extending such methods to general norms and non-Gaussian design matrices. In real world problems, however, covariates are usually corrupted with noise and there have been efforts to generalize structured estimation method for noisy covariate setting. In this paper we first show that without any information about the noise in covariates, currently established techniques of bounding statistical error of estimation fail to provide consistency guarantees. However, when information about noise covariance is available or can be estimated, then we prove consistency guarantees for any norm regularizer, which is a more general result than the state of the art. Next, we investigate empirical performance of structured estimation, specifically LASSO, when covariates are noisy and empirically show that LASSO is not consistent or stable in the presence of additive noise. However, prediction performance improves quite substantially when the noise covariance is available for incorporating in the estimator.}, 
  organization={SIAM}
}